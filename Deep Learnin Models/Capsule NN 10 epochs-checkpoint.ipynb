{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "KA5oO0c1TADD",
    "outputId": "9e23fc08-be22-4c91-b807-ef6373379cf2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow==1.14.0\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FAY7p9FtUP0P"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, os.path\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n7cGiXckUP2n"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rQINSYvIUP4v"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_noaugmentation(imagesArray,imagesLabels,path):\n",
    "    full_path = path+\"live\\\\\"\n",
    "    ImagesPaths = [x for x in os.listdir(full_path)]\n",
    "    \n",
    "    count = 0\n",
    "    for i in ImagesPaths:\n",
    "        img = cv2.imread(full_path+i)\n",
    "        img = cv2.resize(img,(img_width,img_height))\n",
    "        imagesArray[count]= img\n",
    "        imagesLabels[count]=np.array(0)\n",
    "        count+=1\n",
    "        \n",
    "    full_path = path+\"spoof\\\\\"\n",
    "    ImagesPaths = [x for x in os.listdir(full_path)]\n",
    "    \n",
    "    for i in ImagesPaths:\n",
    "        img = cv2.imread(full_path+i)\n",
    "        img = cv2.resize(img,(img_width,img_height))\n",
    "        imagesArray[count]= img\n",
    "        imagesLabels[count]=np.array(1)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives)\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives)\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height, img_num_channels = 50, 50, 3\n",
    "#search about face Pixels\n",
    "\n",
    "\n",
    "input_shape = (img_width, img_height, img_num_channels)\n",
    "pathTrain = 'E:\\\\Python36-32\\\\Face-Recognition-Liveness-Detection\\\\CelebA_Spoof\\\\Data\\\\train\\\\'\n",
    "imagesArrayTrain = np.zeros((2102,img_width,img_height,img_num_channels),dtype = 'float32')\n",
    "imagesLabelsTrain = np.zeros((2102,1),dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTest = 'E:\\\\Python36-32\\\\Face-Recognition-Liveness-Detection\\\\CelebA_Spoof\\\\Data\\\\test\\\\'\n",
    "imagesArrayTest = np.zeros((196,img_width,img_height,img_num_channels),dtype = 'float32')\n",
    "imagesLabelsTest = np.zeros((196,1),dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_noaugmentation(imagesArrayTrain,imagesLabelsTrain,pathTrain)\n",
    "imagesArrayTrain = imagesArrayTrain / 255\n",
    "shuffler = np.random.permutation(len(imagesArrayTrain))\n",
    "imagesArrayTrain_shuffled = imagesArrayTrain[shuffler]\n",
    "imagesLabelsTrain_shuffled = imagesLabelsTrain[shuffler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_noaugmentation(imagesArrayTest,imagesLabelsTest,pathTest)\n",
    "imagesArrayTest = imagesArrayTest / 255\n",
    "shuffler = np.random.permutation(len(imagesArrayTest))\n",
    "X_test = imagesArrayTest[shuffler]\n",
    "y_test = imagesLabelsTest[shuffler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(imagesArrayTrain_shuffled, imagesLabelsTrain_shuffled,stratify=imagesLabelsTrain_shuffled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HIKNVKlxUQBu"
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, 50, 50, 3], dtype=tf.float32, name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6hjQbpLvVWEg"
   },
   "outputs": [],
   "source": [
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps * 17 * 17  # 1152 primary capsules\n",
    "caps1_n_dims = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6a1e743pVWG7"
   },
   "outputs": [],
   "source": [
    "conv1_params = {\n",
    "    \"filters\": 256,\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXqB5Gt8VWI4",
    "outputId": "e0384017-d9a2-4fd9-e22c-3770f76e7e06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-3a2df923b7cc>:1: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001FB5C981278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001FB5C981278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001FB5C981278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001FB5C981278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001FB47D06E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001FB47D06E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001FB47D06E48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001FB47D06E48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qa8fJ-EoVWLi"
   },
   "outputs": [],
   "source": [
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Vs7xQWSaVWNr"
   },
   "outputs": [],
   "source": [
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CH1F6o-5VWP1",
    "outputId": "244c65bc-d9c8-438c-b63c-2d559526b964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-8037c6cbfef1>:4: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "16NzcEKiVWRt"
   },
   "outputs": [],
   "source": [
    "caps2_n_caps = 10\n",
    "caps2_n_dims = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1BqdAB3rVWTl"
   },
   "outputs": [],
   "source": [
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-vhun89RVWWd"
   },
   "outputs": [],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "psFcGB4UVWZB"
   },
   "outputs": [],
   "source": [
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ni31pQ0bVWgW"
   },
   "outputs": [],
   "source": [
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "W95OWK_bVWk0"
   },
   "outputs": [],
   "source": [
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BpWxbnX-Vya6",
    "outputId": "6bf7262d-10f9-4be6-dbbf-3e5fec9e9960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-86a489ae595f>:1: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZC0pT7IgVydF"
   },
   "outputs": [],
   "source": [
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1pDbpj77VyfW"
   },
   "outputs": [],
   "source": [
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "g_ejPa4vVyq1"
   },
   "outputs": [],
   "source": [
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "pTbRDzv7VytF"
   },
   "outputs": [],
   "source": [
    "agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "lVpbtKi2Vyv4"
   },
   "outputs": [],
   "source": [
    "raw_weights_round_2 = tf.add(raw_weights, agreement,\n",
    "                             name=\"raw_weights_round_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HtG9zejMVWnV"
   },
   "outputs": [],
   "source": [
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "hWr045TkV_uI"
   },
   "outputs": [],
   "source": [
    "caps2_output = caps2_output_round_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmz8Y5QVV_wg",
    "outputId": "014a408a-c726-4c6a-d72e-779962ced49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328350, 100)\n"
     ]
    }
   ],
   "source": [
    "def condition(input, counter):\n",
    "    return tf.less(counter, 100)\n",
    "\n",
    "def loop_body(input, counter):\n",
    "    output = tf.add(input, tf.square(counter))\n",
    "    return output, tf.add(counter, 1)\n",
    "\n",
    "with tf.name_scope(\"compute_sum_of_squares\"):\n",
    "    counter = tf.constant(1)\n",
    "    sum_of_squares = tf.constant(0)\n",
    "\n",
    "    result = tf.while_loop(condition, loop_body, [sum_of_squares, counter])\n",
    "    \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "frbd9lY3V_1l"
   },
   "outputs": [],
   "source": [
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-RuzXJZ4V_30"
   },
   "outputs": [],
   "source": [
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "RlOcVjUiV_5e"
   },
   "outputs": [],
   "source": [
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4u40BnzV__R",
    "outputId": "f9fb0b5e-8fda-44b6-f8e7-71262f785de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_pred:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "iWObTQXfWABw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "5Thk-YnAWPI5"
   },
   "outputs": [],
   "source": [
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "nMueL3yrWPK6"
   },
   "outputs": [],
   "source": [
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBPmiiG2WPNn",
    "outputId": "7a1865ad-7447-4603-d1e5-ee024f34ee99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session():\n",
    "    print(T.eval(feed_dict={y: np.array([0, 1, 2, 3, 9])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "oJa4SV15WPSQ"
   },
   "outputs": [],
   "source": [
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "JfgzPUUlWPUQ"
   },
   "outputs": [],
   "source": [
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, 10),\n",
    "                           name=\"present_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "L5yLQq4gWPWZ"
   },
   "outputs": [],
   "source": [
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, 10),\n",
    "                          name=\"absent_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "pTh8RG1cWPYF"
   },
   "outputs": [],
   "source": [
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "lFukfVuAWPZ-"
   },
   "outputs": [],
   "source": [
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "D6TBiey5WPb0"
   },
   "outputs": [],
   "source": [
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "J5U_JlXNWPee"
   },
   "outputs": [],
   "source": [
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "9cgEOI9fWPgY"
   },
   "outputs": [],
   "source": [
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=caps2_n_caps,\n",
    "                                 name=\"reconstruction_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "0ZrWOc4fWjIK"
   },
   "outputs": [],
   "source": [
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "rfUNgde4WjKS"
   },
   "outputs": [],
   "source": [
    "caps2_output_masked = tf.multiply(\n",
    "    caps2_output, reconstruction_mask_reshaped,\n",
    "    name=\"caps2_output_masked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "n4TcTdsoWjPC"
   },
   "outputs": [],
   "source": [
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "lVZfb4oKWjUG"
   },
   "outputs": [],
   "source": [
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = 50 * 50 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0kOxd2rWjWJ",
    "outputId": "e710064c-0437-41a4-93c1-85bab7c1c5f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-55-ca7ebd35d3b1>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001FB43916978>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "87k3zAc5WjYR"
   },
   "outputs": [],
   "source": [
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "x1Tt98JXWjae"
   },
   "outputs": [],
   "source": [
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "jbUygQRdWjcT"
   },
   "outputs": [],
   "source": [
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AS4YdceyWjeL",
    "outputId": "a367a734-0e4a-4827-96a7-a5484ab3d40e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jimmy\\anaconda3\\envs\\TF 114\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "_Sd8whLOW3wk"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.flatten()\n",
    "y_val = y_val.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prec = precision_m(y,y_pred)\n",
    "test_recall =recall_m(y,y_pred)\n",
    "test_f1 = f1_m(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EtXhFdB5W3zK",
    "outputId": "228edeb5-c162-4f3d-c9fe-2bf61eb87d78",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-63-e754ede7c590>:18: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "Epoch: 1  Val accuracy: 97.3810%  Loss: 0.023502 Precision:96.4102564102564% Recall:98.61111111111113% F1_measure:97.34112950360088%  (improved)\n",
      "Epoch: 2  Val accuracy: 98.8095%  Loss: 0.016654 Precision:98.77344877344876% Recall:98.61111111111113% F1_measure:98.60880320507648%  (improved)\n",
      "Epoch: 3  Val accuracy: 98.8095%  Loss: 0.017093 Precision:98.77344877344876% Recall:98.61111111111113% F1_measure:98.60880320507648% \n",
      "Epoch: 4  Val accuracy: 98.8095%  Loss: 0.016671 Precision:98.77344877344876% Recall:98.61111111111113% F1_measure:98.60880320507648% \n",
      "Epoch: 5  Val accuracy: 98.5714%  Loss: 0.016984 Precision:98.73737373737373% Recall:98.17821067821068% F1_measure:98.3829421096502% \n",
      "Epoch: 6  Val accuracy: 98.5714%  Loss: 0.018756 Precision:98.37662337662339% Recall:98.61111111111113% F1_measure:98.40176386760237% \n",
      "Epoch: 7  Val accuracy: 98.5714%  Loss: 0.019182 Precision:97.979797979798% Recall:99.40476190476191% F1_measure:98.6276249630287% \n",
      "Epoch: 8  Val accuracy: 98.5714%  Loss: 0.018662 Precision:97.979797979798% Recall:99.40476190476191% F1_measure:98.6276249630287% \n",
      "Epoch: 9  Val accuracy: 98.8095%  Loss: 0.015447 Precision:98.77344877344876% Recall:98.61111111111113% F1_measure:98.60880320507648%  (improved)\n",
      "Epoch: 10  Val accuracy: 98.8095%  Loss: 0.015242 Precision:98.77344877344876% Recall:98.61111111111113% F1_measure:98.60880320507648%  (improved)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 20\n",
    "restore_checkpoint = True\n",
    "\n",
    "trainLen = len(X_train)\n",
    "valLen = len(X_val)\n",
    "\n",
    "\n",
    "n_iterations_per_epoch = trainLen // batch_size\n",
    "n_iterations_validation = valLen // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch, y_batch = X_train[start:end],y_train[start:end]\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, 50, 50, 3]),\n",
    "                           y: y_batch,\n",
    "                           mask_with_labels: True})\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "            start = start+batch_size\n",
    "            end = end+batch_size\n",
    "\n",
    "        # At the end of each epoch,\n",
    "        # measure the validation loss and accuracy:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        prec_vals = []\n",
    "        recall_vals = []\n",
    "        f1_vals = []\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch, y_batch = X_val[start:end],y_val[start:end]\n",
    "            loss_val, acc_val,prec_test,recall_test,f1_m_test = sess.run(\n",
    "                    [loss, accuracy,test_prec,test_recall,test_f1],\n",
    "                    feed_dict={X: X_batch.reshape([-1,50, 50, 3]),\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            prec_vals.append(prec_test)\n",
    "            recall_vals.append(recall_test)\n",
    "            f1_vals.append(f1_m_test)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "            start = start+batch_size\n",
    "            end = end+batch_size\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        prec_val = np.mean(prec_vals)\n",
    "        recall_val = np.mean(recall_vals)\n",
    "        f1_val = np.mean(f1_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f} Precision:{}% Recall:{}% F1_measure:{}% {}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val, prec_val*100, recall_val*100, f1_val*100,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved:\n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8d4Jz88W34b",
    "outputId": "50e72c5c-9a08-4bfe-e3ea-2c5f9fa9fe47"
   },
   "outputs": [],
   "source": [
    "testLen = len(X_test)\n",
    "\n",
    "n_iterations_test = testLen // batch_size\n",
    "start = 0\n",
    "end = batch_size\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        X_batch, y_batch = X_test[start:end],y_test[start:end]\n",
    "        loss_test, acc_test = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={X: X_batch.reshape([-1, 50, 50, 3]),\n",
    "                           y: y_batch})\n",
    "        loss_tests.append(loss_test)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_test,\n",
    "                  iteration * 100 / n_iterations_test),\n",
    "              end=\" \" * 10)\n",
    "        start = start+batch_size\n",
    "        end = end+batch_size\n",
    "    print(acc_tests)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
    "        acc_test * 100, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUg_tM29W361",
    "outputId": "0749f81e-2a9b-4805-8bf6-e1daba026d30"
   },
   "outputs": [],
   "source": [
    "n_samples = 1\n",
    "\n",
    "img = cv2.imread(\"sample_image.jpg\",cv2.IMREAD_COLOR) \n",
    "sample_images = cv2.resize(img,(img_width,img_height))\n",
    "sample_images = sample_images.reshape([-1, 50, 50, 3])\n",
    "sample_images = sample_images/255\n",
    "print(sample_images)\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    caps2_output_value, decoder_output_value, y_pred_value = sess.run(\n",
    "            [caps2_output, decoder_output, y_pred],\n",
    "            feed_dict={X: sample_images,\n",
    "                       y: np.array([], dtype=np.int64)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6v-Os255W39E",
    "outputId": "d06d07e1-fe18-4055-f6d5-a554c853f2df"
   },
   "outputs": [],
   "source": [
    "\n",
    "sample_images = sample_images.reshape(-1, 50, 50,3)\n",
    "reconstructions = decoder_output_value.reshape([-1, 50, 50,3])\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.imshow(sample_images[index], cmap=\"binary\")\n",
    "    plt.title(\"Label:\" + str(X_test[index]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    plt.title(\"Predicted:\" + str(y_pred_value[index]))\n",
    "    plt.imshow(reconstructions[index], cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXcJuPytW3_d",
    "outputId": "01241bb1-ea9c-4478-957b-969423ba06e1"
   },
   "outputs": [],
   "source": [
    "caps2_output_value.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pigjOrczjggR"
   },
   "outputs": [],
   "source": [
    "def tweak_pose_parameters(output_vectors, min=-0.5, max=0.5, n_steps=11):\n",
    "    steps = np.linspace(min, max, n_steps) # -0.25, -0.15, ..., +0.25\n",
    "    pose_parameters = np.arange(caps2_n_dims) # 0, 1, ..., 15\n",
    "    tweaks = np.zeros([caps2_n_dims, n_steps, 1, 1, 1, caps2_n_dims, 1])\n",
    "    tweaks[pose_parameters, :, 0, 0, 0, pose_parameters, 0] = steps\n",
    "    output_vectors_expanded = output_vectors[np.newaxis, np.newaxis]\n",
    "    return tweaks + output_vectors_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbsR7jxUjgir"
   },
   "outputs": [],
   "source": [
    "n_steps = 11\n",
    "\n",
    "tweaked_vectors = tweak_pose_parameters(caps2_output_value, n_steps=n_steps)\n",
    "tweaked_vectors_reshaped = tweaked_vectors.reshape(\n",
    "    [-1, 1, caps2_n_caps, caps2_n_dims, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vx5s3GHMjglU",
    "outputId": "4ee883db-d0b3-41ba-f0d7-e4b4eec826b0"
   },
   "outputs": [],
   "source": [
    "tweak_labels = np.tile(mnist.test.labels[:n_samples], caps2_n_dims * n_steps)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    decoder_output_value = sess.run(\n",
    "            decoder_output,\n",
    "            feed_dict={caps2_output: tweaked_vectors_reshaped,\n",
    "                       mask_with_labels: True,\n",
    "                       y: tweak_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5iWG9HvW4CG"
   },
   "outputs": [],
   "source": [
    "tweak_reconstructions = decoder_output_value.reshape(\n",
    "        [caps2_n_dims, n_steps, n_samples, 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "F3pRgHlajlec",
    "outputId": "bc0eb25e-6582-4eb5-c1d5-6eb8ae86947e"
   },
   "outputs": [],
   "source": [
    "for dim in range(3):\n",
    "    print(\"Tweaking output dimension #{}\".format(dim))\n",
    "    plt.figure(figsize=(n_steps / 1.2, n_samples / 1.5))\n",
    "    for row in range(n_samples):\n",
    "        for col in range(n_steps):\n",
    "            plt.subplot(n_samples, n_steps, row * n_steps + col + 1)\n",
    "            plt.imshow(tweak_reconstructions[dim, col, row], cmap=\"binary\")\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
